# ComfyUI ä¾¿æºç‰ˆ `llama-cpp-python` CUDA å®‰è£…æŒ‡å—

æœ¬æŒ‡å—å¸®åŠ©æ‚¨ä¸º ComfyUI çš„ Windows ä¾¿æºç‰ˆå®‰è£…æ”¯æŒ GPU (CUDA) çš„ `llama-cpp-python`ã€‚

---

### **1. æ‰“å¼€ ComfyUI çš„å‘½ä»¤æç¤ºç¬¦**

* è¿›å…¥ `C:\ComfyUI_windows_portable\python_embeded`
* åœ¨åœ°å€æ ä¸­è¾“å…¥ `cmd` å¹¶æŒ‰å›è½¦é”®ã€‚

---

### **2. å®‰è£…æ„å»ºå·¥å…·ï¼ˆå¦‚æœå°šæœªå®‰è£…ï¼‰**

* **å®‰è£… Visual Studio Build Toolsï¼š**
    * ä» [https://visualstudio.microsoft.com/downloads/](https://visualstudio.microsoft.com/downloads/) ä¸‹è½½ï¼ˆåœ¨"Tools for Visual Studio"ä¸‹ï¼‰ã€‚
    * è¿è¡Œå®‰è£…ç¨‹åºï¼Œé€‰æ‹© **"Desktop development with C++"** å·¥ä½œè´Ÿè½½ã€‚
* **å®‰è£… NVIDIA CUDA Toolkitï¼š**
    * ä» [https://developer.nvidia.com/cuda-toolkit-archive](https://developer.nvidia.com/cuda-toolkit-archive) ä¸‹è½½æ‚¨çš„ CUDA ç‰ˆæœ¬ï¼ˆä¾‹å¦‚ 12.6ï¼‰ã€‚
    * è¿è¡Œå®‰è£…ç¨‹åºï¼Œç¡®ä¿é€‰ä¸­ **"Visual Studio Integration"**ã€‚

## **è‡ªåŠ¨å®‰è£…è„šæœ¬ï¼ˆæ¨èï¼‰**

* ç¡®ä¿å®‰è£…è„šæœ¬ä¿å­˜åœ¨è¿™é‡Œï¼š  
  `.\ComfyUI\custom_nodes\ComfyUI-MiniCPM\install_llama_official.py`

* åœ¨å‘½ä»¤æç¤ºç¬¦ä¸­ï¼ˆåœ¨æ­¥éª¤ 1 ä¸­æ‰“å¼€çš„ï¼‰ï¼Œè¿è¡Œè„šæœ¬ï¼š

  ```bash
  .\python_embeded\python.exe llama_cpp_install.py
  ```

è„šæœ¬å°†æ‰§è¡Œä»¥ä¸‹æ“ä½œï¼š

* å‡çº§ pip
* æ¸…é™¤ pip ç¼“å­˜
* å®‰è£…æœ€å°æ„å»ºä¾èµ–é¡¹ï¼ˆscikit-build-core, cmakeï¼‰
* æ£€æµ‹ GPU å¹¶åœ¨å¯ç”¨æ—¶æ„å»ºæ”¯æŒ CUDA çš„ llama-cpp-python

ğŸ•’ æ­¤è¿‡ç¨‹å¯èƒ½éœ€è¦ 5-20+ åˆ†é’Ÿï¼Œå…·ä½“å–å†³äºæ‚¨çš„ç³»ç»Ÿã€‚

### **é‡å¯ ComfyUI**

* å…³é—­ ComfyUIã€‚
* é‡å¯ ComfyUIã€‚
* ä½¿ç”¨ Ctrl+F5ï¼ˆWindowsï¼‰æˆ– Cmd+Shift+Rï¼ˆmacOSï¼‰ç¡¬åˆ·æ–°æµè§ˆå™¨ã€‚

## **æ‰‹åŠ¨å®‰è£…**
---

### **1. å‡†å¤‡ Python ç¯å¢ƒ**

* åœ¨å‘½ä»¤æç¤ºç¬¦ä¸­è¿è¡Œï¼š
    ```bash
    .\python.exe -m pip install --upgrade pip
    .\python.exe -m pip cache purge
    .\python.exe -m pip install scikit-build-core cmake
    ```

---

### **2. ç¼–è¯‘å¹¶å®‰è£… `llama-cpp-python`**

* åœ¨å‘½ä»¤æç¤ºç¬¦ä¸­è¿è¡Œï¼š
    ```bash
    set CMAKE_ARGS="-DGGML_CUDA=on" && .\python.exe -m pip install llama-cpp-python --no-cache-dir && set CMAKE_ARGS=
    ```
    * **è€å¿ƒç­‰å¾…ã€‚** è¿™éœ€è¦æ—¶é—´ï¼ˆ5-20+ åˆ†é’Ÿï¼‰ã€‚

---

### **3. é‡å¯ ComfyUI**

* å…³é—­ ComfyUIã€‚
* é‡å¯ ComfyUIã€‚
* ç¡¬åˆ·æ–°ç½‘é¡µæµè§ˆå™¨ï¼ˆ`Ctrl+F5` æˆ– `Cmd+Shift+R`ï¼‰ã€‚

--- 